{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0150283a",
   "metadata": {},
   "source": [
    "# PROGRAMMING1 - FINAL ASSIGNMENT\n",
    "## Comparing two RNA quantification methods - NanoDrop vs TapeStation\n",
    "#### Jennefer Beenen - Data Science for Life Sciences - January 2023\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Background\n",
    "Isolated RNA needs to be quantified in order to have the correct amount of starting input for RNA library preparation for sequencing. The input used for library prep. can i.e. have a range from 5 - 200 ng, where the optimal can be at 100 ng.\n",
    "\n",
    "The research sequencing facility (RSF) has two devices for RNA quantification, of which both use a different methods:\n",
    "- [NanoDrop 2000](https://www.thermofisher.com/order/catalog/product/ND-2000) (ThermoFisher) measures light intensity in a range of different light wavelengths. [Manual](https://assets.thermofisher.com/TFS-Assets/CAD/manuals/NanoDrop-2000-User-Manual-EN.pdf)\n",
    "- [TapeStation 4200](https://www.agilent.com/en/product/automated-electrophoresis/tapestation-systems/tapestation-instruments/4200-tapestation-system-228263) (Agilent) measures fluorescently stained fragements that are separated by electrophoresis. [Manual](http://download.chem.agilent.com/software/4200_tapestation_user_info_package_v2/tapestation%20user%20information/tapestation%20manuals/agilent%204200%20tapestation%20system%20manual_g2991-90000.pdf)\n",
    "  \n",
    "  Agilent provides two different RNA kits for the TapeStation:\n",
    "  - [High Sensitivity RNA](https://www.agilent.com/en/product/automated-electrophoresis/tapestation-systems/tapestation-rna-screentape-reagents/high-sensitivity-rna-screentape-analysis-228267), Quantitative Range of 0.5 - 10 ng/µL\n",
    "  - [Standard RNA](https://www.agilent.com/en/product/automated-electrophoresis/tapestation-systems/tapestation-rna-screentape-reagents/rna-screentape-analysis-228268), Quantitative Range of 25 - 500 ng/µL\n",
    "\n",
    "### Aim of this assignment (research question)\n",
    "What makes that both methods (NanoDrop and TapeStation) sometimes differ in outcome?\n",
    "\n",
    "Variables: 260/280 ratio’s (NanoDrop), 260/230 ratio’s (NanoDrop), RNA Integrity Number (RIN) (TapeStation), and used kit (TapeStation).\n",
    "\n",
    "  <details>    \n",
    "  <summary>\n",
    "  <font size=\"3\" color=\"lightblue\">Ratio's explained</font>\n",
    "  </summary>\n",
    "  260/280 ratio\n",
    "  <blockquote>\n",
    "  The ratio of absorbance at 260 and 280 nm is used to\n",
    "  assess the purity of DNA and RNA. A ratio of ~1.8 is generally accepted as “pure” for DNA; a ratio of ~2.0 is\n",
    "  generally accepted as “pure” for RNA. If the ratio is appreciably lower in either case, it may indicate the\n",
    "  presence of protein, phenol or other contaminants that absorb strongly at or near 280 nm.\n",
    "  </blockquote>\n",
    "  260/230 ratio\n",
    "  <blockquote>\n",
    "  This is a secondary measure of nucleic acid purity.\n",
    "  The 260/230 values for a “pure” nucleic acid are often higher than the respective 260/280 values and are\n",
    "  commonly in the range of 1.8-2.2. If the ratio is appreciably lower, this may indicate the presence of co-\n",
    "  purified contaminants.\n",
    "  </blockquote>\n",
    "  See NanoDrop manual as reference.\n",
    "  </details>\n",
    "\n",
    ">\n",
    "\n",
    "  <details>    \n",
    "  <summary>\n",
    "  <font size=\"3\" color=\"lightblue\">RIN explained</font>\n",
    "  </summary>\n",
    "  <blockquote>\n",
    "  RINe is calculated at a scale from 1 to 10. \n",
    "  A high RINe indicates highly intact RNA, and a low\n",
    "  RINe a strongly degraded RNA sample.\n",
    "  </blockquote>\n",
    "   https://www.agilent.com/cs/library/technicaloverviews/public/5991-6616EN.pdf\n",
    "  </details>\n",
    "\n",
    "### Data description\n",
    "The datasets can be found [here](https://unishare.nl/index.php/s/j78cSJc5gXQidLy). It is password protected which Jennefer can provide.\n",
    "\n",
    "A staff member of the RSF (Rianna Arjaans) already gathered information of both methods (TODO: Hoe heeft ze dat gedaan??) and placed it in one excel sheet (see 'TS_vs_ND_new.xlsx' in 'original' folder). Total number of entries are 260. \n",
    "\n",
    "Since for this assignment multiple sources needs to be used, this sheet was manually split by Jennefer into 3 seperate files:\n",
    "\n",
    "- Nanodrop.xlsx\n",
    "  - Sample, sample name.\n",
    "  - dil. Factor, dilution factor used for getting sample in detection range of used methods of the TS.\n",
    "  - Nanodrop (ng/ul), concentration of stock sample measured by the NanoDrop.\n",
    "  - Naodrop dil. (ng/ul), concentration of diluted sample measured by the NanoDrop.\n",
    "  - Cal. Conc. (ng/ul), calculated concentration of `Nanodrop dil. (ng/ul)` multiplied by the `dil. Factor`.\n",
    "  - 260/280 ratio (~2.0), ratio of absorbance at 260 nm and 280 nm.\n",
    "  - 260/230 ratio (2.0-2.2), ratio of absorbance at 260 nm and 230 nm.\n",
    ">\n",
    "\n",
    "- TapeStation.xlsx\n",
    "  - Sample, sample name.\n",
    "  - dil. Factor, dilution factor used for getting sample in detection range of used methods.\n",
    "  - TS (ng/ul), concentration measured by the TapeStation.\n",
    "  - Cal. Conc (ng/ul), calculated concentration of `TS (ng/ul)` multiplied by the `dil. Factor`.\n",
    "  - RIN, RNA Integrity Number.\n",
    "  - TS type, which TapeStation RNA kit was used; HS is High Sensitivity, SS is Standard Sensitivity.\n",
    ">\n",
    "\n",
    "- meta.xlsx \n",
    "  - Sample, sample name.\n",
    "  - dil. Factor, dilution factor used for getting sample in detection range of used methods.\n",
    "  - nM library, nano Molarity of output library preparation.\n",
    "  - `unnamed column`, comments.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15eb6ab9",
   "metadata": {},
   "source": [
    "### Assessment criteria\n",
    "\n",
    "Conditional\n",
    "- No data and or api-key information is stored in the repository. \n",
    "- No hard datapaths are used, datapaths are provided in a configfile.\n",
    "- At least two data sets are merged into one tidy dataframe.\n",
    "\n",
    "Graded\n",
    "- ~~(5 pt) The research question is stated.~~\n",
    "- ~~(5 pt) Links to sources are provided and a small description about the data~~\n",
    "- (20 pt) Data qualitity and data quantity are inspected and reported. Appropiate transformations are applied.\n",
    "- (20 pt) **Assumptions and presuppositions are made explicit** (chosen data storage method, chosen analysis method, chosen design). An argumentative approach is used explaining steps, taken into account data quality and quantity. Explanation is provided either with comments in the code or in a seperate document.\n",
    "- (10 pt) Interactive visualization is extracted from correct analysis of (incomplete) data\n",
    "- (10 pt) The design supports the research question. The data is informative in relation to the topic. Visualization is functional and attractive **Figures contain X and Y labels, title and captions**. (10)\n",
    "- (20 pt) Code is efficient coded, according to coding style without code smells and easy to read. Code is demonstrated robust and flexible \n",
    "- (10 pt) All the code is stored in repository with **Readme including most relevant information to implement the code.** used software is suitably licensed and documented\n",
    "\n",
    "- **Comment what you can expect, and comment the results**\n",
    "- **If you use code snippets from others you should refer to the original author, otherwise you will be accused of plagiarism. Please be prepared to explain your code in a verbal exam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaafcb9",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "- Define a research question, select data and code your data acquisition, data processing, data analysis and visualization. \n",
    "- Use a repository with a commit strategy and write a readme file. \n",
    "- Make sure that you document your choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f657fb",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07215f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get folder_path from config.yaml\n",
    "with open('config.yaml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "folder_path = config['filepath_final']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e69b7117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invisible_folder will not be transformed into a DataFrame, for it does not end with '.xlsx'.\n",
      "Total of 3 DataFrames were generated.\n"
     ]
    }
   ],
   "source": [
    "def all_excel_files_to_df(folder_path):\n",
    "    \"\"\"\n",
    "    all_excel_files_to_df() will return a list containing DataFrames of all '.xlsx' files in folder_path\n",
    "\n",
    "    folder_path = string to which folder the function should look into for files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all ls_file_names in folder_path\n",
    "    ls_file_names = os.listdir(folder_path)\n",
    "\n",
    "    # Make a list (ls_of_dfs) containing [file_name, DataFrames of file_name] from folder_path if file_name ends with '.xlsx'.\n",
    "    # file_name is added to the list for reporting troubleshooting info later on.\n",
    "    # Return a usefull message if an error occures during the process.\n",
    "    ls_of_dfs = []\n",
    "\n",
    "    for file_name in ls_file_names:\n",
    "\n",
    "        if os.path.splitext(file_name)[1] == '.xlsx':\n",
    "            \n",
    "            try:\n",
    "                df_temp = pd.read_excel(folder_path + file_name)\n",
    "                ls_of_dfs.append([file_name, df_temp]) \n",
    "\n",
    "            except:\n",
    "                print('An error occured while pd.read_excel(file_name) was executed.')\n",
    "\n",
    "        else:\n",
    "            print(f\"{file_name} will not be transformed into a DataFrame, for it does not end with '.xlsx'.\")\n",
    "\n",
    "    print(f'Total of {len(ls_of_dfs)} DataFrames were generated.')\n",
    "    return ls_of_dfs\n",
    "\n",
    "\"\"\"I think this way of converting files to DataFrames is a bit over done for this application, \n",
    "but I already finished the code when I thought about it. I think for this particular application \n",
    "it would be better to have a variable in the config.yaml where the user can enter which files \n",
    "needed to be converted to a DataFrame separated by a comma. \n",
    "There is no need to look into all the files in this directory. It actually makes it more error prone.\"\"\"\n",
    "\n",
    "# Make a list (ls_of_dfs) containing DataFrames of all '.xlsx' files in folder_path\n",
    "ls_of_dfs = all_excel_files_to_df(folder_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b2382b7",
   "metadata": {},
   "source": [
    "#### Inspecting how to merge\n",
    "\n",
    "(Would it be possible to store DataFrames as a 'value' in pandas?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5f9e3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'dil. Factor']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return common column names.\n",
    "\n",
    "for n, df in enumerate(ls_of_dfs):\n",
    "\n",
    "    # First fills temp_set1 with the column names of the first DataFrame, \n",
    "    if n == 0:\n",
    "        temp_set1 = set(df[1].columns)    \n",
    "\n",
    "    # then compare it with column names of all other DataFrames.\n",
    "    else:\n",
    "        temp_set1 = temp_set1 & set(df[1].columns)\n",
    "\n",
    "common_columns = list(temp_set1)\n",
    "common_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fb74f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used in the next block.\n",
    "# It is used to find indexes of values that cause an 'error'.\n",
    "# Code was modified from:\n",
    "# https://stackoverflow.com/questions/33938488/finding-the-index-of-an-element-in-nested-lists-in-python\n",
    "\n",
    "def index_value_in_list(my_list, value):\n",
    "    \"\"\"\n",
    "    index_value_in_list() will return a list with indexes where value was found.\n",
    "    my_list = a max. 2 level deep list, i.e. [['a', 'b', 'c', 'e'], ['d', 'e', 'f'], ['g', 'h']].\n",
    "    value = value to be searched for.\n",
    "    \"\"\"\n",
    "    index_list = []\n",
    "    for n, sub_list in enumerate(my_list):\n",
    "        if value in sub_list:\n",
    "            index = [n, sub_list.index(value)]\n",
    "            index_list.append(index)\n",
    "\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32529478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the common columns are the same.\n",
      "DataFrames are ready to be merged.\n"
     ]
    }
   ],
   "source": [
    "# Compare if all df the common_columns share the same values.\n",
    "\n",
    "false_counter = 0\n",
    "for n, df in enumerate(ls_of_dfs):\n",
    "\n",
    "    # First fills temp_set2 with all values of the common columns of the first DataFrame, \n",
    "    if n == 0:\n",
    "        temp_set2 = df[1][common_columns].values\n",
    "\n",
    "    # then compare it with all values of the common columns of all other DataFrames.\n",
    "    else:\n",
    "        # If value is not the same and therefore False, it will add 1 to the false_counter\n",
    "        # And report which file and lines generated a False\n",
    "        if False in (df[1][common_columns].values == temp_set2):\n",
    "            false_counter += 1\n",
    "            false_list = (df[1][common_columns].values == temp_set2).tolist()\n",
    "            \n",
    "            print(f\"\"\"There is value discrepancy in file {df[0]}.\n",
    "Index can be found below.\n",
    "column reference: {common_columns}\n",
    "[row#, column#]\n",
    "\"\"\")\n",
    "            print(index_value_in_list(false_list, False))\n",
    "            \n",
    "           \n",
    "# If no false_counter == 0, the DataFrames can be merged \n",
    "if false_counter == 0:\n",
    "    print('All values in the common columns are the same.\\nDataFrames are ready to be merged.')\n",
    "else:\n",
    "    print('\\nPlease resolve value discrepancy (check if values are correct, or exclude file).')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298087ca",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f86695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype\n",
    "# quality inspected and reported.\n",
    "# missing values\n",
    "# outliers (PLOT?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77262fa",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity inspected and reported.\n",
    "# distribution (PLOT)\n",
    "# test significance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b8bb0",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f486b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272bebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5267afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9400f6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b91fa5cffef32cb10787a50fea9666676a7951181e01280b4644cd70c964bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
